{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlB2cpNTF_Mw",
        "outputId": "b9eaa92b-5ce4-41cb-83ba-fb19eec1eb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsEPvsikFGp9",
        "outputId": "8002044c-06f5-4cbe-a721-d359027d3030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU not available\n",
            "Found 384 validated image filenames belonging to 2 classes.\n",
            "Found 96 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "12/12 [==============================] - 311s 17s/step - loss: 0.1020 - accuracy: 0.9401 - val_loss: 5.4447e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 191s 16s/step - loss: 0.0797 - accuracy: 0.9922 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 194s 16s/step - loss: 0.0731 - accuracy: 0.9844 - val_loss: 6.8132e-07 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 194s 16s/step - loss: 0.0179 - accuracy: 0.9974 - val_loss: 4.0243e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 194s 16s/step - loss: 6.5999e-06 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 190s 16s/step - loss: 0.0018 - accuracy: 0.9974 - val_loss: 0.0036 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 190s 16s/step - loss: 3.9959e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 194s 16s/step - loss: 1.3037e-06 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 189s 15s/step - loss: 4.0525e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 189s 15s/step - loss: 5.8678e-07 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 194s 16s/step - loss: 8.0876e-08 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 188s 15s/step - loss: 1.3961e-06 - accuracy: 1.0000 - val_loss: 8.8492e-04 - val_accuracy: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 188s 15s/step - loss: 6.6801e-08 - accuracy: 1.0000 - val_loss: 7.4633e-04 - val_accuracy: 1.0000 - lr: 4.0000e-05\n",
            "96/96 [==============================] - 23s 178ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.45      0.45      0.45        49\n",
            "    Positive       0.43      0.43      0.43        47\n",
            "\n",
            "    accuracy                           0.44        96\n",
            "   macro avg       0.44      0.44      0.44        96\n",
            "weighted avg       0.44      0.44      0.44        96\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import NASNetMobile\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check if TensorFlow can access the GPU\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU available\")\n",
        "else:\n",
        "    print(\"GPU not available\")\n",
        "\n",
        "# Define the paths to your dataset\n",
        "data_dir = '/content/drive/MyDrive/Laboratory'\n",
        "positive_dir = os.path.join(data_dir, 'Positive')\n",
        "negative_dir = os.path.join(data_dir, 'Negative')\n",
        "\n",
        "# Create lists to store file paths and labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "# Read the Positive images\n",
        "for file in os.listdir(positive_dir):\n",
        "    file_paths.append(os.path.join(positive_dir, file))\n",
        "    labels.append(1)  # Label for positive images\n",
        "\n",
        "# Read the Negative images\n",
        "for file in os.listdir(negative_dir):\n",
        "    file_paths.append(os.path.join(negative_dir, file))\n",
        "    labels.append(0)  # Label for negative images\n",
        "\n",
        "# Convert to numpy arrays\n",
        "file_paths = np.array(file_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to a list of strings\n",
        "labels = labels.astype(str).tolist()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# ImageDataGenerator for data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Helper function to create a data generator\n",
        "def create_generator(file_paths, labels, datagen, batch_size=32):\n",
        "    return datagen.flow_from_dataframe(\n",
        "        dataframe=pd.DataFrame({'filename': file_paths, 'class': labels}),\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Create generators for training and testing\n",
        "train_generator = create_generator(train_paths, train_labels, train_datagen)\n",
        "test_generator = create_generator(test_paths, test_labels, test_datagen, batch_size=1)  # Set batch_size to 1 for testing\n",
        "\n",
        "# Load the NASNetMobile model with pre-trained ImageNet weights\n",
        "base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Add dropout layer for regularization\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler and early stopping callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=30,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator),\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_labels = np.array(test_labels)\n",
        "test_labels = test_labels.astype(int)\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "predictions = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calculate performance metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, predictions, target_names=['Negative', 'Positive']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdKuG0zuFYFO",
        "outputId": "73e3da58-38e5-44e7-bc14-83addfdb524c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 46.88%\n",
            "Precision: 25.00%\n",
            "Recall: 4.26\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix , accuracy_score, precision_score, recall_score\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "precision = precision_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "print(f'Recall: {recall * 100:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}